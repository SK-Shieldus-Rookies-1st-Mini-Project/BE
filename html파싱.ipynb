{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51ff82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619755f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing(url):\n",
    "     #요청 헤더 설정 : 브라우저 정보\n",
    "    req_header = {\n",
    "        \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    # requests 의 get() 함수 호출하기 \n",
    "    res=requests.get(url,headers=req_header)\n",
    "    res.encoding = 'utf-8'\n",
    "\n",
    "    # 응답(response)이 OK 이면 text 추출\n",
    "    if res.ok:\n",
    "        html = res.text\n",
    "        # url에서 파일명만 추출하기\n",
    "        file_name = os.path.basename(url)\n",
    "        # BeautifulSoup 객체 생성\n",
    "        soup = BeautifulSoup(html, \"html.parser\")  \n",
    "        result_set = soup.select('ul.list_newsheadline2 li')\n",
    "        print(type(result_set),len(result_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6befd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "import os\n",
    "\n",
    "def parse_filename_from_direct_url(url):\n",
    "    \"\"\"\n",
    "    URL이 직접적인 파일 경로일 때 파일 이름을 파싱합니다.\n",
    "    \"\"\"\n",
    "    parsed_url = urlparse(url)\n",
    "    # URL 경로에서 마지막 부분을 가져옵니다.\n",
    "    path = parsed_url.path\n",
    "    # os.path.basename은 경로의 마지막 구성 요소를 반환합니다.\n",
    "    filename = os.path.basename(path)\n",
    "    return filename\n",
    "\n",
    "# 예시\n",
    "url1 = \"http://example.com/documents/report.pdf\"\n",
    "url2 = \"https://www.google.com/images/branding/googlelogo/1x/googlelogo_color_272x92dp.png\"\n",
    "url3 = \"http://example.com/index.html\" # HTML 파일도 결국은 파일이름이 있습니다.\n",
    "\n",
    "print(f\"URL: {url1} -> File Name: {parse_filename_from_direct_url(url1)}\")\n",
    "print(f\"URL: {url2} -> File Name: {parse_filename_from_direct_url(url2)}\")\n",
    "print(f\"URL: {url3} -> File Name: {parse_filename_from_direct_url(url3)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f58ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files found on https://math-son.tistory.com/1387: ['2026%20%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95%20%EC%98%81%EC%96%B4%EB%8F%85%ED%95%B4%EC%97%B0%EC%8A%B5.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EC%96%B8%EC%96%B4%EC%99%80_%EB%A7%A4%EC%B2%B4_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EC%98%81%EC%96%B4_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '9946E6465CDBC72506', '2026%20%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95%20%EB%AF%B8%EC%A0%81%EB%B6%84.pdf.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EB%AC%B8%ED%95%99_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EC%84%B8%EA%B3%84%EC%82%AC_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4%20(2).pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EC%82%AC%ED%9A%8C%EB%AC%B8%ED%99%94_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EC%98%81%EC%96%B4%EB%8F%85%ED%95%B4%EC%97%B0%EC%8A%B5_%EB%8B%A8%EC%96%B4%EC%9E%A5.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EC%A0%95%EC%B9%98%EC%99%80_%EB%B2%95_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EB%AF%B8%EC%A0%81%EB%B6%84_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026%20%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%20%EB%AC%B8%ED%95%99.zip', '2026%20%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95%20%EB%AC%BC%EB%A6%AC%ED%95%99%E2%85%A0.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95__%EB%8F%85%EC%84%9C_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EA%B8%B0%ED%95%98_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%ED%99%94%ED%95%99%E2%85%A0_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026%20%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95%20%EC%88%98%ED%95%99%E2%85%A0.pdf.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EC%A7%80%EA%B5%AC%EA%B3%BC%ED%95%99%E2%85%A1_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EC%84%B8%EA%B3%84%EC%A7%80%EB%A6%AC_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026%20%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%20%ED%99%94%ED%95%992.pdf', '2026%20%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95%20%EA%B8%B0%ED%95%98.pdf.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%ED%95%9C%EA%B5%AD%EC%82%AC_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EB%AC%BC%EB%A6%AC%ED%95%99%E2%85%A1_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EC%83%9D%EB%AA%85%EA%B3%BC%ED%95%99%E2%85%A0_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EC%98%81%EC%96%B4%EB%8F%85%ED%95%B4%EC%97%B0%EC%8A%B5_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EA%B2%BD%EC%A0%9C_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4%20(2).pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EB%8F%99%EC%95%84%EC%8B%9C%EC%95%84%EC%82%AC_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026%20%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95%20%EC%98%81%EC%96%B4(%EC%98%81%EB%8B%A8%EC%96%B4%EC%88%99%EC%96%B4).pdf', '2026%20%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EC%98%81%EC%96%B4.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EC%A7%80%EA%B5%AC%EA%B3%BC%ED%95%99%E2%85%A0_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026%20%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%20%ED%95%9C%EA%B5%AD%EC%82%AC.zip', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EB%AC%BC%EB%A6%AC%ED%95%99%E2%85%A0_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026%20%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%20%EB%8F%85%EC%84%9C.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EC%88%98%ED%95%99%E2%85%A1_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026%20%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95%20%EB%AC%BC%EB%A6%AC%ED%95%99%E2%85%A1.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EC%98%81%EC%96%B4%EB%93%A3%EA%B8%B0_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EC%83%9D%EB%AA%85%EA%B3%BC%ED%95%99%E2%85%A1_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%ED%99%95%EB%A5%A0%EA%B3%BC_%ED%86%B5%EA%B3%84_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EC%83%9D%ED%99%9C%EA%B3%BC_%EC%9C%A4%EB%A6%AC_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026%20%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95%20%ED%99%94%ED%95%991.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%ED%99%94%EB%B2%95%EA%B3%BC_%EC%9E%91%EB%AC%B8_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EC%88%98%ED%95%99%E2%85%A0_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%EC%9C%A4%EB%A6%AC%EC%99%80_%EC%82%AC%EC%83%81_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf', '2026%20%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95%20%ED%99%95%EB%A5%A0%EA%B3%BC%20%ED%86%B5%EA%B3%84.pdf.pdf', '2026%20%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95%20%EC%88%98%ED%95%99%E2%85%A1.pdf.pdf', '2026_%EC%88%98%EB%8A%A5%ED%8A%B9%EA%B0%95_%ED%99%94%ED%95%99%E2%85%A1_%EC%A0%95%EB%8B%B5%EA%B3%BC%ED%95%B4%EC%84%A4.pdf']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import os\n",
    "\n",
    "def parse_filenames_from_html_page(url):\n",
    "    \"\"\"\n",
    "    웹페이지의 HTML을 파싱하여 파일 링크(PDF, 이미지, 등)를 찾고 파일 이름을 추출합니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status() # HTTP 오류 발생 시 예외 발생\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        found_filenames = set() # 중복 제거를 위해 set 사용\n",
    "\n",
    "        # 1. <a> 태그의 href 속성에서 파일 확장자를 가진 링크 찾기\n",
    "        # 일반적인 문서/미디어 파일 확장자를 추가할 수 있습니다.\n",
    "        file_extensions = ('.pdf', '.doc', '.docx', '.xls', '.xlsx', '.ppt', '.pptx',\n",
    "                           '.zip', '.rar', '.tar', '.gz', '.7z', 'exe',\n",
    "                           '.jpg', '.jpeg', '.png', '.gif', '.svg', '.mp4', '.mp3')\n",
    "\n",
    "        for a_tag in soup.find_all('a', href=True):\n",
    "            href = a_tag['href']\n",
    "            # 절대 URL로 변환하여 상대 경로도 처리 가능\n",
    "            abs_url = urljoin(url, href)\n",
    "            if abs_url.lower().endswith(file_extensions):\n",
    "                filename = os.path.basename(urlparse(abs_url).path)\n",
    "                if filename: # 빈 문자열이 아닌 경우에만 추가\n",
    "                    found_filenames.add(filename)\n",
    "\n",
    "        # 2. <img> 태그의 src 속성에서 파일 이름 찾기\n",
    "        for img_tag in soup.find_all('img', src=True):\n",
    "            src = img_tag['src']\n",
    "            abs_url = urljoin(url, src)\n",
    "            filename = os.path.basename(urlparse(abs_url).path)\n",
    "            if filename:\n",
    "                found_filenames.add(filename)\n",
    "\n",
    "        # 3. <source> 태그 (video/audio)\n",
    "        for source_tag in soup.find_all('source', src=True):\n",
    "            src = source_tag['src']\n",
    "            abs_url = urljoin(url, src)\n",
    "            filename = os.path.basename(urlparse(abs_url).path)\n",
    "            if filename:\n",
    "                found_filenames.add(filename)\n",
    "        #4. <div> 태그 \n",
    "        for source_tag in soup.find_all('div', src=True):\n",
    "            src = source_tag['src']\n",
    "            abs_url = urljoin(url, src)\n",
    "            filename = os.path.basename(urlparse(abs_url).path)\n",
    "            if filename:\n",
    "                found_filenames.add(filename)\n",
    "\n",
    "        return list(found_filenames) # set을 list로 변환하여 반환\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL {url}: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "current_url = \"https://math-son.tistory.com/1387\"\n",
    "filenames = parse_filenames_from_html_page(current_url)\n",
    "print(f\"\\nFiles found on {current_url}: {filenames}\")\n",
    "\n",
    "\n",
    "# # 단순 설명을 위한 URL 예시\n",
    "# print(\"\\n--- HTML 페이지 파싱 예시 ---\")\n",
    "# # 실제 요청은 하지 않고, HTML 문자열을 직접 파싱하여 시연\n",
    "# html_content_for_test = \"\"\"\n",
    "# <html>\n",
    "# <body>\n",
    "#     <a href=\"http://example.com/documents/report.pdf\">Download PDF</a>\n",
    "#     <img src=\"/images/logo.png\">\n",
    "#     <a href=\"/data/archive.zip\">Archive File</a>\n",
    "#     <a href=\"javascript:void(0);\">No File Here</a>\n",
    "#     <a href=\"https://other.com/photos/image.jpg\">External Image</a>\n",
    "# </body>\n",
    "# </html>\n",
    "# \"\"\"\n",
    "# soup_test = BeautifulSoup(html_content_for_test, 'html.parser')\n",
    "# test_url_base = \"http://example.com/\" # 상대 경로 처리를 위한 기본 URL\n",
    "\n",
    "# found_filenames_manual = set()\n",
    "# file_extensions = ('.pdf', '.doc', '.docx', '.xls', '.xlsx', '.ppt', '.pptx',\n",
    "#                    '.zip', '.rar', '.tar', '.gz', '.7z',\n",
    "#                    '.jpg', '.jpeg', '.png', '.gif', '.svg', '.mp4', '.mp3')\n",
    "\n",
    "# for tag in soup_test.find_all(['a', 'img', 'source']):\n",
    "#     src_or_href = tag.get('href') or tag.get('src')\n",
    "#     if src_or_href:\n",
    "#         abs_url = urljoin(test_url_base, src_or_href)\n",
    "#         if abs_url.lower().endswith(file_extensions):\n",
    "#             filename = os.path.basename(urlparse(abs_url).path)\n",
    "#             if filename:\n",
    "#                 found_filenames_manual.add(filename)\n",
    "\n",
    "# print(f\"Manually parsed filenames: {list(found_filenames_manual)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
